{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# EEG Data Processing\n",
        "\n",
        "This notebook handles the preprocessing of EEG data where each channel contains time series data stored as string arrays.\n",
        "\n",
        "Key features:\n",
        "1. Parsing string arrays into numerical values\n",
        "2. Computing representative values for each channel\n",
        "3. Handling missing and invalid data\n",
        "4. Label encoding for classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from typing import List, Union, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Определение каналов ЭЭГ\n",
        "EXPECTED_CHANNELS = [\n",
        "    'A1', 'A2',             # Референтные электроды\n",
        "    'C3', 'C4', 'Cz',      # Центральные\n",
        "    'F3', 'F4', 'F7', 'F8', # Фронтальные\n",
        "    'Fp1', 'Fp2', 'Fpz',    # Префронтальные\n",
        "    'Fz',                   # Фронтальный средний\n",
        "    'O1', 'O2',            # Затылочные\n",
        "    'P3', 'P4', 'Pz',      # Теменные\n",
        "    'T3', 'T4', 'T5', 'T6' # Височные\n",
        "]\n",
        "\n",
        "def parse_array_string(s: str) -> np.ndarray:\n",
        "    \"\"\"Преобразование строки с массивом в numpy array.\"\"\"\n",
        "    try:\n",
        "        # Очистка строки\n",
        "        s = s.strip()\n",
        "        if s.startswith('[') and s.endswith(']'):\n",
        "            # Удаляем скобки и разделяем по запятой\n",
        "            values = s[1:-1].split(',')\n",
        "            # Конвертируем в float\n",
        "            return np.array([float(v.strip()) for v in values], dtype=np.float32)\n",
        "        return np.array([float(s)], dtype=np.float32)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing: {s[:50]}... Error: {str(e)}\")\n",
        "        return np.array([np.nan], dtype=np.float32)\n",
        "\n",
        "def process_channel_value(value: Union[str, float, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Обработка значения канала ЭЭГ.\n",
        "    Возвращает временной ряд как numpy array.\n",
        "    \"\"\"\n",
        "    if pd.isna(value):\n",
        "        return np.array([np.nan])\n",
        "    \n",
        "    try:\n",
        "        if isinstance(value, (int, float)):\n",
        "            return np.array([float(value)])\n",
        "        \n",
        "        if isinstance(value, str):\n",
        "            return parse_array_string(value)\n",
        "        \n",
        "        return np.array([np.nan])\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error processing value: {str(e)}\")\n",
        "        return np.array([np.nan])\n",
        "\n",
        "def validate_data(data: np.ndarray, name: str = \"\") -> np.ndarray:\n",
        "    \"\"\"Валидация и очистка данных.\"\"\"\n",
        "    print(f\"\\nValidating {name}:\")\n",
        "    print(f\"Shape: {data.shape}\")\n",
        "    print(f\"dtype: {data.dtype}\")\n",
        "    \n",
        "    # Проверка на некорректные значения\n",
        "    nan_mask = np.isnan(data)\n",
        "    inf_mask = np.isinf(data)\n",
        "    \n",
        "    if nan_mask.any() or inf_mask.any():\n",
        "        print(f\"Found invalid values:\")\n",
        "        print(f\"NaN count: {nan_mask.sum()}\")\n",
        "        print(f\"Inf count: {inf_mask.sum()}\")\n",
        "        \n",
        "        # Заменяем некорректные значения\n",
        "        invalid_mask = nan_mask | inf_mask\n",
        "        valid_data = data[~invalid_mask]\n",
        "        \n",
        "        if valid_data.size > 0:\n",
        "            fill_value = np.mean(valid_data)\n",
        "        else:\n",
        "            fill_value = 0.0\n",
        "            \n",
        "        data[invalid_mask] = fill_value\n",
        "        \n",
        "    return data.astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка и подготовка данных\n",
        "print(\"Loading data...\")\n",
        "try:\n",
        "    # Загрузка данных\n",
        "    df = pd.read_csv('/home/belyaeva.a/df_open.csv')\n",
        "    print(\"DataFrame shape:\", df.shape)\n",
        "    \n",
        "    # Создание словаря для преобразования меток в индексы\n",
        "    unique_labels = df['label'].unique()\n",
        "    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    print(\"\\nFound classes:\", unique_labels.tolist())\n",
        "    \n",
        "    # Предварительная обработка данных\n",
        "    print(\"\\nPreprocessing data...\")\n",
        "    processed_channels = {}\n",
        "    sequence_lengths = []  # Для отслеживания длины временных рядов\n",
        "    \n",
        "    # Обработка каждого канала отдельно\n",
        "    for col in EXPECTED_CHANNELS:\n",
        "        print(f\"\\nProcessing channel {col}...\")\n",
        "        channel_data = df[col].copy()\n",
        "        \n",
        "        # Анализ данных канала\n",
        "        print(f\"Channel type: {channel_data.dtype}\")\n",
        "        print(f\"NaN values: {channel_data.isna().sum()}\")\n",
        "        \n",
        "        # Преобразование данных канала\n",
        "        channel_sequences = []\n",
        "        for value in channel_data:\n",
        "            seq = process_channel_value(value)\n",
        "            channel_sequences.append(seq)\n",
        "            sequence_lengths.append(len(seq))\n",
        "        \n",
        "        processed_channels[col] = channel_sequences\n",
        "    \n",
        "    # Определение максимальной длины последовательности\n",
        "    max_seq_length = max(sequence_lengths)\n",
        "    min_seq_length = min(sequence_lengths)\n",
        "    print(f\"\\nSequence length statistics:\")\n",
        "    print(f\"Min length: {min_seq_length}\")\n",
        "    print(f\"Max length: {max_seq_length}\")\n",
        "    \n",
        "    # Создание трехмерного массива (n_samples, n_channels, sequence_length)\n",
        "    n_samples = len(df)\n",
        "    n_channels = len(EXPECTED_CHANNELS)\n",
        "    \n",
        "    # Инициализация массива данных\n",
        "    X = np.zeros((n_samples, n_channels, max_seq_length), dtype=np.float32)\n",
        "    \n",
        "    # Заполнение массива данными\n",
        "    for i, channel in enumerate(EXPECTED_CHANNELS):\n",
        "        for j, seq in enumerate(processed_channels[channel]):\n",
        "            # Если последовательность короче максимальной, заполняем оставшееся место последним значением\n",
        "            seq_len = len(seq)\n",
        "            X[j, i, :seq_len] = seq\n",
        "            if seq_len < max_seq_length:\n",
        "                X[j, i, seq_len:] = seq[-1]\n",
        "    \n",
        "    # Преобразование меток\n",
        "    y = np.array([label_to_idx[label] for label in df['label']])\n",
        "    \n",
        "    print(\"\\nFinal data information:\")\n",
        "    print(f\"X shape: {X.shape}\")  # (n_samples, n_channels, sequence_length)\n",
        "    print(f\"X dtype: {X.dtype}\")\n",
        "    print(f\"Sample of X (first channel, first 5 timepoints):\\n{X[0, 0, :5]}\")\n",
        "    print(f\"Label mapping:\", label_to_idx)\n",
        "    print(f\"y shape: {y.shape}\")\n",
        "    \n",
        "    # Сохранение обработанных данных\n",
        "    np.save('processed_X.npy', X)\n",
        "    np.save('processed_y.npy', y)\n",
        "    np.save('label_mapping.npy', label_to_idx)\n",
        "    print(\"\\nProcessed data saved to 'processed_X.npy', 'processed_y.npy', and 'label_mapping.npy'\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nError during data loading and preprocessing: {str(e)}\")\n",
        "    print(\"\\nDetailed error information:\")\n",
        "    if 'df' in locals():\n",
        "        print(f\"DataFrame shape: {df.shape}\")\n",
        "        print(f\"Column types:\\n{df[EXPECTED_CHANNELS].dtypes}\")\n",
        "        print(\"\\nSample of raw data:\")\n",
        "        for col in EXPECTED_CHANNELS[:2]:\n",
        "            print(f\"\\n{col}:\")\n",
        "            print(df[col].iloc[0])\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
